{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Human Computer Interaction CS449 – CS549\n",
    "\n",
    "Assignment 5: Development of Gesture-based interaction using Mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1733682915.681392 2649799 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M2\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1733682915.692675 2649945 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1733682915.695390 2649942 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1733682915.708544 2649944 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lütfen sabit durun, kalibrasyon başlıyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 21:35:16.121 Python[53742:2649799] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2024-12-08 21:35:16.121 Python[53742:2649799] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kalibrasyon tamamlandı: Default Yaw = 0.01, Default Pitch = 1.09\n",
      "Min Sağ Yaw = -0.08\n",
      "Max Sol Yaw = 0.09\n",
      "Max Yukarı Pitch = 0.27\n",
      "Min Aşağı Pitch = -0.32\n",
      "Kalibrasyon tamamlandı!\n",
      "Baş sağa çevrildi!\n",
      "Baş sağa çevrildi!\n",
      "Baş sola çevrildi!\n",
      "Baş yukarı kaldırıldı!\n",
      "Baş aşağı indirildi!\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# MediaPipe için modüller\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "\n",
    "# Landmark index'leri\n",
    "NOSE_TIP = 1\n",
    "LEFT_EAR = 234\n",
    "RIGHT_EAR = 454\n",
    "CHIN = 152\n",
    "\n",
    "# Kalibrasyon için veriler\n",
    "default_yaw = 0\n",
    "default_pitch = 0\n",
    "yaw_range = {\"left\": 0, \"right\": 0}\n",
    "pitch_range = {\"up\": 0, \"down\": 0}\n",
    "\n",
    "yaw_values = []\n",
    "pitch_values = []\n",
    "calibration_step = 0  # 0: varsayılan, 1: sağa, 2: sola, 3: yukarı, 4: aşağı\n",
    "\n",
    "# Hareket doğrulama\n",
    "last_movement = None\n",
    "movement_start_time = None\n",
    "movement_confirmation_time = 2  # Kullanıcının hareketi doğrulamak için beklemesi gereken süre (saniye)\n",
    "\n",
    "\n",
    "# Kalibrasyon işlevi\n",
    "def calibrate_yaw_pitch(yaw, pitch):\n",
    "    global calibration_step, default_yaw, default_pitch, yaw_range, pitch_range, yaw_values, pitch_values\n",
    "\n",
    "    if calibration_step == 0 and len(yaw_values) == 0:\n",
    "        print(\"Lütfen sabit durun, kalibrasyon başlıyor...\")\n",
    "\n",
    "    if calibration_step == 0:  # Varsayılan pozisyon\n",
    "        yaw_values.append(yaw)\n",
    "        pitch_values.append((chin[1] - nose[1]) / (right_ear[0] - left_ear[0]))\n",
    "        if len(yaw_values) >= 200:  # Daha fazla veri alıyoruz\n",
    "            default_yaw = np.mean(yaw_values)\n",
    "            default_pitch = np.mean(pitch_values)  # Default pitch ayarlanır\n",
    "            print(f\"Kalibrasyon tamamlandı: Default Yaw = {default_yaw:.2f}, Default Pitch = {default_pitch:.2f}\")\n",
    "            yaw_values.clear()\n",
    "            pitch_values.clear()\n",
    "            calibration_step = 1  # Sağa çevirme\n",
    "\n",
    "    elif calibration_step == 1:  # Sağa çevirme\n",
    "        yaw_values.append(yaw)\n",
    "        if len(yaw_values) >= 100:  # Daha fazla veri alıyoruz\n",
    "            yaw_range[\"right\"] = min(yaw_values)  # Sağ için min değer\n",
    "            print(f\"Min Sağ Yaw = {yaw_range['right']:.2f}\")\n",
    "            yaw_values.clear()\n",
    "            calibration_step = 2  # Sola çevirme\n",
    "\n",
    "    elif calibration_step == 2:  # Sola çevirme\n",
    "        yaw_values.append(yaw)\n",
    "        if len(yaw_values) >= 100:\n",
    "            yaw_range[\"left\"] = max(yaw_values)  # Sol için max değer\n",
    "            print(f\"Max Sol Yaw = {yaw_range['left']:.2f}\")\n",
    "            yaw_values.clear()\n",
    "            calibration_step = 3  # Yukarı bakma\n",
    "\n",
    "    elif calibration_step == 3:  # Yukarı bakma\n",
    "        pitch_values.append(pitch)\n",
    "        if len(pitch_values) >= 100:\n",
    "            pitch_range[\"up\"] = max(pitch_values)  # Yukarı için min değer\n",
    "            print(f\"Max Yukarı Pitch = {pitch_range['up']:.2f}\")\n",
    "            pitch_values.clear()\n",
    "            calibration_step = 4  # Aşağı bakma\n",
    "\n",
    "    elif calibration_step == 4:  # Aşağı bakma\n",
    "        pitch_values.append(pitch)\n",
    "        if len(pitch_values) >= 100:\n",
    "            pitch_range[\"down\"] = min(pitch_values)  # Aşağı için max değer\n",
    "            print(f\"Min Aşağı Pitch = {pitch_range['down']:.2f}\")\n",
    "            print(\"Kalibrasyon tamamlandı!\")\n",
    "            calibration_step = -1  # Kalibrasyon tamamlandı\n",
    "\n",
    "\n",
    "def detect_head_movement(yaw, pitch):\n",
    "    global default_yaw, default_pitch, yaw_range, pitch_range, last_movement, movement_start_time\n",
    "\n",
    "    current_movement = None\n",
    "\n",
    "    # Yaw hareketi algılama\n",
    "    if yaw <= yaw_range[\"right\"] / 2:  # Sağ için min değer\n",
    "        current_movement = \"Baş sağa çevrildi!\"\n",
    "    elif yaw >= yaw_range[\"left\"] / 2:  # Sol için max değer\n",
    "        current_movement = \"Baş sola çevrildi!\"\n",
    "\n",
    "    # Pitch hareketi algılama\n",
    "    if pitch <= pitch_range[\"down\"] / 2:  # Aşağı için min değer\n",
    "        current_movement = \"Baş aşağı indirildi!\"\n",
    "    elif pitch >= pitch_range[\"up\"] / 2:  # Yukarı için max değer\n",
    "        current_movement = \"Baş yukarı kaldırıldı!\"\n",
    "\n",
    "    # Hareketi doğrulama\n",
    "    if current_movement == last_movement:\n",
    "        if movement_start_time is None:\n",
    "            movement_start_time = time.time()\n",
    "        elif time.time() - movement_start_time >= movement_confirmation_time:\n",
    "            if current_movement:  # Sadece bir hareket varsa yazdır\n",
    "                print(current_movement)\n",
    "            movement_start_time = None  # Doğrulandıktan sonra sıfırla\n",
    "    else:\n",
    "        last_movement = current_movement\n",
    "        movement_start_time = None  # Yeni hareket için zamanlayıcıyı sıfırla\n",
    "\n",
    "\n",
    "# Kamerayı aç\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "with mp_face_mesh.FaceMesh(\n",
    "        min_detection_confidence=0.7,\n",
    "        min_tracking_confidence=0.7) as face_mesh:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Kamera bulunamadı!\")\n",
    "            break\n",
    "\n",
    "        # Renk uzayını değiştir\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = face_mesh.process(frame_rgb)\n",
    "\n",
    "        if results.multi_face_landmarks:\n",
    "            for face_landmarks in results.multi_face_landmarks:\n",
    "                # Landmark'ların koordinatlarını al\n",
    "                landmarks = face_landmarks.landmark\n",
    "                nose = np.array([landmarks[NOSE_TIP].x, landmarks[NOSE_TIP].y])\n",
    "                left_ear = np.array([landmarks[LEFT_EAR].x, landmarks[LEFT_EAR].y])\n",
    "                right_ear = np.array([landmarks[RIGHT_EAR].x, landmarks[RIGHT_EAR].y])\n",
    "                chin = np.array([landmarks[CHIN].x, landmarks[CHIN].y])\n",
    "\n",
    "                # Yaw ve Pitch hesaplama\n",
    "                yaw = nose[0] - ((left_ear[0] + right_ear[0]) / 2)  # Daha hassas yaw hesaplama\n",
    "\n",
    "                # Yaw ve Pitch hesaplama\n",
    "                yaw = nose[0] - ((left_ear[0] + right_ear[0]) / 2)  # Daha hassas yaw hesaplama\n",
    "\n",
    "                # Daha hassas pitch hesaplama ve normalize etme\n",
    "                pitch = ((chin[1] - nose[1]) / (right_ear[0] - left_ear[0])) - default_pitch  # Default pitch değerini sıfırlama\n",
    "\n",
    "                # Kalibrasyonu yönet\n",
    "                calibrate_yaw_pitch(yaw, pitch)\n",
    "\n",
    "                # Kalibrasyon sonrası hareket algılama\n",
    "                if calibration_step == -1:\n",
    "                    detect_head_movement(yaw, pitch)\n",
    "\n",
    "                # Bilgileri ekrana yazdır\n",
    "                cv2.putText(frame, f\"Yaw: {yaw:.2f}, Pitch: {pitch:.2f}\",\n",
    "                            (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 4)\n",
    "\n",
    "                # Kullanıcıya görsel mesajlar\n",
    "                if calibration_step == 1:\n",
    "                    cv2.putText(frame, \"Lutfen basinizi saga cevirin.\",\n",
    "                                (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 4)\n",
    "                elif calibration_step == 2:\n",
    "                    cv2.putText(frame, \"Lutfen basinizi sola cevirin.\",\n",
    "                                (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 4)\n",
    "                elif calibration_step == 3:\n",
    "                    cv2.putText(frame, \"Lutfen basinizi yukari kaldirin.\",\n",
    "                                (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 4)\n",
    "                elif calibration_step == 4:\n",
    "                    cv2.putText(frame, \"Lutfen basinizi asagi indirin.\",\n",
    "                                (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 4)\n",
    "                elif calibration_step == -1:\n",
    "                    cv2.putText(frame, \"Kalibrasyon tamamlandı!\",\n",
    "                                (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 4)\n",
    "\n",
    "        # Kamerayı göster\n",
    "        cv2.imshow(\"Bas Hareketleri Algilama\", frame)\n",
    "\n",
    "        # Çıkmak için 'q' tuşuna basın\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
