{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 22:39:31.200 Python[57583:2702256] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2024-12-08 22:39:31.200 Python[57583:2702256] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PyQt5.QtWidgets import QApplication, QLabel\n",
    "\n",
    "app = QApplication([])\n",
    "label = QLabel(\"PyQt5 Yüklü ve Çalışıyor!\")\n",
    "label.show()\n",
    "app.exec_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1733688137.429884 2731751 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M2\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1733688137.432908 2732059 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1733688137.435686 2732062 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "2024-12-08 23:02:18.940 Python[60162:2731751] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2024-12-08 23:02:18.941 Python[60162:2731751] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n",
      "W0000 00:00:1733688139.047777 2732065 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 43\u001b[0m, in \u001b[0;36mCameraFeed.update_frame\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_frame\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 43\u001b[0m     ret, frame \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ret:\n\u001b[1;32m     45\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import sys\n",
    "from PyQt5.QtWidgets import QApplication, QLabel, QVBoxLayout, QWidget\n",
    "from PyQt5.QtGui import QImage, QPixmap\n",
    "from PyQt5.QtCore import QTimer, Qt  # Qt buraya eklendi\n",
    "\n",
    "# Mediapipe için modüller\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "\n",
    "# Kamera sınıfı\n",
    "class CameraFeed(QWidget):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.setWindowTitle(\"Test Arayüzü\")\n",
    "        self.setGeometry(100, 100, 800, 600)\n",
    "        \n",
    "        # Kamera görüntüsü için QLabel\n",
    "        self.camera_label = QLabel(self)\n",
    "        self.camera_label.resize(400, 300)\n",
    "        \n",
    "        # Arayüz alanı için QLabel\n",
    "        self.interface_label = QLabel(self)\n",
    "        self.interface_label.resize(400, 300)\n",
    "        self.interface_label.move(400, 0)\n",
    "        self.interface_label.setStyleSheet(\"background-color: lightgray; border: 1px solid black;\")\n",
    "        self.interface_label.setText(\"Arayüz Alanı\")\n",
    "        self.interface_label.setAlignment(Qt.AlignCenter)  # Qt burada kullanılıyor\n",
    "        \n",
    "        # Timer\n",
    "        self.timer = QTimer(self)\n",
    "        self.timer.timeout.connect(self.update_frame)\n",
    "        \n",
    "        # Mediapipe FaceMesh\n",
    "        self.face_mesh = mp_face_mesh.FaceMesh(min_detection_confidence=0.7, min_tracking_confidence=0.7)\n",
    "        \n",
    "        # Kamera\n",
    "        self.cap = cv2.VideoCapture(0)\n",
    "        self.timer.start(20)  # 50 FPS\n",
    "        \n",
    "    def update_frame(self):\n",
    "        ret, frame = self.cap.read()\n",
    "        if not ret:\n",
    "            return\n",
    "        \n",
    "        # BGR -> RGB\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Mediapipe ile yüz analizi\n",
    "        results = self.face_mesh.process(rgb_frame)\n",
    "        \n",
    "        if results.multi_face_landmarks:\n",
    "            for face_landmarks in results.multi_face_landmarks:\n",
    "                for id, landmark in enumerate(face_landmarks.landmark):\n",
    "                    h, w, c = frame.shape\n",
    "                    x, y = int(landmark.x * w), int(landmark.y * h)\n",
    "                    \n",
    "                    # Burun ucu koordinatları\n",
    "                    if id == 1:  # Örneğin burun ucu\n",
    "                        cv2.circle(frame, (x, y), 5, (0, 255, 0), -1)\n",
    "        \n",
    "        # Görüntüyü QLabel'e aktar\n",
    "        h, w, ch = frame.shape\n",
    "        bytes_per_line = ch * w\n",
    "        qt_image = QImage(frame.data, w, h, bytes_per_line, QImage.Format_RGB888)\n",
    "        pixmap = QPixmap.fromImage(qt_image)\n",
    "        self.camera_label.setPixmap(pixmap)\n",
    "        \n",
    "    def closeEvent(self, event):\n",
    "        self.cap.release()\n",
    "        self.face_mesh.close()\n",
    "        event.accept()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app = QApplication(sys.argv)\n",
    "    main_window = CameraFeed()\n",
    "    main_window.show()\n",
    "    sys.exit(app.exec_())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1733688348.904055 2734787 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M2\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1733688348.906362 2734905 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1733688348.908846 2734904 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1733688350.462882 2734905 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n",
      "2024-12-08 23:05:50.500 Python[60315:2734787] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2024-12-08 23:05:50.500 Python[60315:2734787] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ulasyildiz/Documents/Gesture-Based Interaction/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import sys\n",
    "from PyQt5.QtWidgets import QApplication, QLabel, QWidget\n",
    "from PyQt5.QtGui import QImage, QPixmap\n",
    "from PyQt5.QtCore import QTimer, Qt, QElapsedTimer\n",
    "\n",
    "# Mediapipe için modüller\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "\n",
    "class CameraFeed(QWidget):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.setWindowTitle(\"Test Arayüzü\")\n",
    "        self.setGeometry(100, 100, 1280, 720)\n",
    "        \n",
    "        # Kamera görüntüsü için QLabel\n",
    "        self.camera_label = QLabel(self)\n",
    "        self.camera_label.resize(640, 480)\n",
    "        self.camera_label.setScaledContents(True)\n",
    "        \n",
    "        # Arayüz alanı için QLabel\n",
    "        self.interface_label = QLabel(self)\n",
    "        self.interface_label.resize(640, 480)\n",
    "        self.interface_label.move(640, 0)\n",
    "        self.interface_label.setStyleSheet(\"background-color: lightgray; border: 1px solid black;\")\n",
    "        self.interface_label.setText(\"Arayüz Alanı\")\n",
    "        self.interface_label.setAlignment(Qt.AlignCenter)\n",
    "        \n",
    "        # Timer\n",
    "        self.timer = QTimer(self)\n",
    "        self.timer.timeout.connect(self.update_frame)\n",
    "        \n",
    "        # Mediapipe FaceMesh\n",
    "        self.face_mesh = mp_face_mesh.FaceMesh(min_detection_confidence=0.7, min_tracking_confidence=0.7)\n",
    "        \n",
    "        # Kamera\n",
    "        self.cap = cv2.VideoCapture(0)\n",
    "        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "        self.timer.start(20)\n",
    "        \n",
    "        # İmleç pozisyonu ve seçim zamanı\n",
    "        self.cursor_x, self.cursor_y = 0, 0\n",
    "        self.start_time = None\n",
    "        self.selected_area = None\n",
    "\n",
    "    def update_frame(self):\n",
    "        ret, frame = self.cap.read()\n",
    "        if not ret:\n",
    "            return\n",
    "\n",
    "        # Görüntüyü yatay eksende çevir\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        \n",
    "        # BGR -> RGB\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Mediapipe ile yüz analizi\n",
    "        results = self.face_mesh.process(rgb_frame)\n",
    "        \n",
    "        if results.multi_face_landmarks:\n",
    "            for face_landmarks in results.multi_face_landmarks:\n",
    "                h, w, c = frame.shape\n",
    "                nose = face_landmarks.landmark[1]\n",
    "                self.cursor_x = int(nose.x * w)\n",
    "                self.cursor_y = int(nose.y * h)\n",
    "                \n",
    "                # İmleç pozisyonu\n",
    "                cv2.circle(frame, (self.cursor_x, self.cursor_y), 10, (255, 0, 0), -1)\n",
    "                \n",
    "                # Seçim alanı kontrolü\n",
    "                self.check_selection()\n",
    "\n",
    "        # Görüntüyü QLabel'e aktar\n",
    "        h, w, ch = rgb_frame.shape\n",
    "        bytes_per_line = ch * w\n",
    "        qt_image = QImage(rgb_frame.data, w, h, bytes_per_line, QImage.Format_RGB888)\n",
    "        pixmap = QPixmap.fromImage(qt_image)\n",
    "        self.camera_label.setPixmap(pixmap)\n",
    "\n",
    "    def check_selection(self):\n",
    "        # İmleç arayüz alanında mı?\n",
    "        if 640 <= self.cursor_x <= 1280 and 0 <= self.cursor_y <= 480:\n",
    "            if self.start_time is None:\n",
    "                self.start_time = QElapsedTimer()\n",
    "                self.start_time.start()\n",
    "            elif self.start_time.elapsed() > 3000:  # 3 saniye geçti mi?\n",
    "                self.selected_area = \"Arayüz Seçildi!\"\n",
    "                self.interface_label.setStyleSheet(\"background-color: lightblue; border: 1px solid black;\")\n",
    "                print(self.selected_area)\n",
    "                self.start_time = None\n",
    "        else:\n",
    "            self.start_time = None\n",
    "            self.interface_label.setStyleSheet(\"background-color: lightgray; border: 1px solid black;\")\n",
    "\n",
    "    def keyPressEvent(self, event):\n",
    "        if event.key() == Qt.Key_Q:  # Kullanıcı 'q' tuşuna bastığında\n",
    "            self.close()  # Pencereyi kapat\n",
    "        \n",
    "    def closeEvent(self, event):\n",
    "        self.cap.release()\n",
    "        self.face_mesh.close()\n",
    "        event.accept()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app = QApplication(sys.argv)\n",
    "    main_window = CameraFeed()\n",
    "    main_window.show()\n",
    "    sys.exit(app.exec_())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1733689852.074104 2745697 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M2\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1733689852.076313 2745790 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1733689852.078801 2745787 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "2024-12-08 23:30:53.584 Python[60858:2745697] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2024-12-08 23:30:53.584 Python[60858:2745697] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n",
      "W0000 00:00:1733689853.616889 2745788 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ulasyildiz/Documents/Gesture-Based Interaction/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import sys\n",
    "from PyQt5.QtWidgets import QApplication, QLabel, QWidget, QVBoxLayout\n",
    "from PyQt5.QtGui import QImage, QPixmap, QPainter, QColor\n",
    "from PyQt5.QtCore import QTimer, Qt, QPoint\n",
    "\n",
    "# Mediapipe için modüller\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "\n",
    "class CameraFeed(QWidget):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.setWindowTitle(\"Göz İmleci ve Arayüz\")\n",
    "        self.setGeometry(100, 100, 1280, 720)\n",
    "        \n",
    "        # Ana layout\n",
    "        self.layout = QVBoxLayout(self)\n",
    "        \n",
    "        # Kamera görüntüsü için QLabel\n",
    "        self.camera_label = QLabel(self)\n",
    "        self.camera_label.setFixedSize(1280, 480)\n",
    "        self.camera_label.setStyleSheet(\"border: 1px solid black;\")\n",
    "        self.layout.addWidget(self.camera_label)\n",
    "        \n",
    "        # Arayüz alanı\n",
    "        self.interface_label = QLabel(self)\n",
    "        self.interface_label.setFixedSize(1280, 240)\n",
    "        self.interface_label.setStyleSheet(\"background-color: lightgray; border: 1px solid black;\")\n",
    "        self.layout.addWidget(self.interface_label)\n",
    "        \n",
    "        # İmleç pozisyonu bilgisi\n",
    "        self.cursor_label = QLabel(self.interface_label)\n",
    "        self.cursor_label.setText(\"Göz İmleci Koordinatları: X: 0, Y: 0\")\n",
    "        self.cursor_label.setStyleSheet(\"font-size: 16px; color: green;\")\n",
    "        self.cursor_label.move(10, 10)\n",
    "\n",
    "        # Timer\n",
    "        self.timer = QTimer(self)\n",
    "        self.timer.timeout.connect(self.update_frame)\n",
    "        \n",
    "        # Mediapipe FaceMesh\n",
    "        self.face_mesh = mp_face_mesh.FaceMesh(min_detection_confidence=0.7, min_tracking_confidence=0.7)\n",
    "        \n",
    "        # Kamera\n",
    "        self.cap = cv2.VideoCapture(0)\n",
    "        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "        self.timer.start(20)\n",
    "        \n",
    "        # Göz imleci pozisyonu\n",
    "        self.cursor_x, self.cursor_y = 0, 0\n",
    "\n",
    "    def update_frame(self):\n",
    "        ret, frame = self.cap.read()\n",
    "        if not ret:\n",
    "            return\n",
    "\n",
    "        # Görüntüyü yatay eksende çevir\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        \n",
    "        # BGR -> RGB\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Mediapipe ile yüz analizi\n",
    "        results = self.face_mesh.process(rgb_frame)\n",
    "        \n",
    "        if results.multi_face_landmarks:\n",
    "            for face_landmarks in results.multi_face_landmarks:\n",
    "                h, w, c = frame.shape\n",
    "                nose = face_landmarks.landmark[1]\n",
    "                self.cursor_x = int(nose.x * w)\n",
    "                self.cursor_y = int(nose.y * h)\n",
    "                \n",
    "                # Göz imleci pozisyonu\n",
    "                relative_x = self.cursor_x % self.interface_label.width()\n",
    "                relative_y = self.cursor_y % self.interface_label.height()\n",
    "                self.cursor_label.setText(f\"Göz İmleci Koordinatları: X: {relative_x}, Y: {relative_y}\")\n",
    "                \n",
    "                # İmleci arayüzde göster\n",
    "                self.repaint_interface_label(relative_x, relative_y)\n",
    "\n",
    "        # Görüntüyü QLabel'e aktar\n",
    "        h, w, ch = rgb_frame.shape\n",
    "        bytes_per_line = ch * w\n",
    "        qt_image = QImage(rgb_frame.data, w, h, bytes_per_line, QImage.Format_RGB888)\n",
    "        pixmap = QPixmap.fromImage(qt_image)\n",
    "        self.camera_label.setPixmap(pixmap)\n",
    "        \n",
    "    def repaint_interface_label(self, x, y):\n",
    "        pixmap = QPixmap(self.interface_label.size())\n",
    "        pixmap.fill(Qt.transparent)\n",
    "        \n",
    "        painter = QPainter(pixmap)\n",
    "        painter.setBrush(QColor(255, 0, 0))\n",
    "        painter.setPen(Qt.NoPen)\n",
    "        painter.drawEllipse(QPoint(x, y), 10, 10)\n",
    "        painter.end()\n",
    "        \n",
    "        self.interface_label.setPixmap(pixmap)\n",
    "\n",
    "    def keyPressEvent(self, event):\n",
    "        if event.key() == Qt.Key_Q:  # Kullanıcı 'q' tuşuna bastığında\n",
    "            self.close()  # Pencereyi kapat\n",
    "        \n",
    "    def closeEvent(self, event):\n",
    "        self.cap.release()\n",
    "        self.face_mesh.close()\n",
    "        event.accept()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app = QApplication(sys.argv)\n",
    "    main_window = CameraFeed()\n",
    "    main_window.show()\n",
    "    sys.exit(app.exec_())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1733693530.409798 2795006 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M2\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1733693530.411788 2795090 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1733693530.416913 2795090 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1733693532.109072 2795087 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n",
      "2024-12-09 00:32:12.146 Python[63356:2795006] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2024-12-09 00:32:12.146 Python[63356:2795006] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ulasyildiz/Documents/Gesture-Based Interaction/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import sys\n",
    "from PyQt5.QtWidgets import QApplication, QLabel, QWidget, QVBoxLayout\n",
    "from PyQt5.QtGui import QImage, QPixmap, QPainter, QColor\n",
    "from PyQt5.QtCore import QTimer, Qt, QPoint\n",
    "\n",
    "# Mediapipe için modüller\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "\n",
    "class CameraFeed(QWidget):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.setWindowTitle(\"Göz İmleci ve Arayüz\")\n",
    "        self.setGeometry(100, 100, 1280, 720)\n",
    "        \n",
    "        # Ana layout\n",
    "        self.layout = QVBoxLayout(self)\n",
    "        \n",
    "        # Kamera görüntüsü için QLabel\n",
    "        self.camera_label = QLabel(self)\n",
    "        self.camera_label.setFixedSize(320, 180)  # Daha küçük bir alan için\n",
    "        self.camera_label.setStyleSheet(\"border: 1px solid black;\")\n",
    "        self.layout.addWidget(self.camera_label)\n",
    "        \n",
    "        # Arayüz alanı\n",
    "        self.interface_label = QLabel(self)\n",
    "        self.interface_label.setFixedSize(1280, 540)  # Arayüz için daha büyük alan\n",
    "        self.interface_label.setStyleSheet(\"background-color: lightgray; border: 1px solid black;\")\n",
    "        self.layout.addWidget(self.interface_label)\n",
    "        \n",
    "        # İmleç pozisyonu bilgisi\n",
    "        self.cursor_label = QLabel(self.interface_label)\n",
    "        self.cursor_label.setText(\"Göz İmleci Koordinatları: X: 0, Y: 0\")\n",
    "        self.cursor_label.setStyleSheet(\"font-size: 16px; color: green;\")\n",
    "        self.cursor_label.move(10, 10)\n",
    "\n",
    "        # Timer\n",
    "        self.timer = QTimer(self)\n",
    "        self.timer.timeout.connect(self.update_frame)\n",
    "        \n",
    "        # Mediapipe FaceMesh\n",
    "        self.face_mesh = mp_face_mesh.FaceMesh(refine_landmarks=True,  # Daha hassas iris verileri\n",
    "                                               min_detection_confidence=0.7, \n",
    "                                               min_tracking_confidence=0.7)\n",
    "        \n",
    "        # Kamera\n",
    "        self.cap = cv2.VideoCapture(0)\n",
    "        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "        self.timer.start(20)\n",
    "        \n",
    "        # Göz imleci pozisyonu\n",
    "        self.cursor_x, self.cursor_y = 0, 0\n",
    "\n",
    "    def update_frame(self):\n",
    "        ret, frame = self.cap.read()\n",
    "        if not ret:\n",
    "            return\n",
    "\n",
    "        # Görüntüyü yatay eksende çevir\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        \n",
    "        # BGR -> RGB\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Mediapipe ile yüz analizi\n",
    "        results = self.face_mesh.process(rgb_frame)\n",
    "        \n",
    "        if results.multi_face_landmarks:\n",
    "            for face_landmarks in results.multi_face_landmarks:\n",
    "                h, w, c = frame.shape\n",
    "                # Sağ ve sol iris merkezlerini alın\n",
    "                left_eye_center = face_landmarks.landmark[468]  # Sol iris merkezi\n",
    "                right_eye_center = face_landmarks.landmark[473]  # Sağ iris merkezi\n",
    "                \n",
    "                # Daha hassas hareket için faktör\n",
    "                sensitivity_x = 1.8  # X ekseni hassasiyeti\n",
    "                sensitivity_y = 1.8  # Y ekseni hassasiyeti\n",
    "                self.cursor_x = int(left_eye_center.x * self.interface_label.width() * sensitivity_x)\n",
    "                self.cursor_y = int(left_eye_center.y * self.interface_label.height() * sensitivity_y)\n",
    "                \n",
    "                # Koordinatları göster\n",
    "                self.cursor_label.setText(f\"Göz İmleci Koordinatları: X: {self.cursor_x}, Y: {self.cursor_y}\")\n",
    "                \n",
    "                # İmleci arayüzde göster\n",
    "                self.repaint_interface_label(self.cursor_x, self.cursor_y)\n",
    "\n",
    "        # Görüntüyü QLabel'e aktar\n",
    "        h, w, ch = rgb_frame.shape\n",
    "        bytes_per_line = ch * w\n",
    "        qt_image = QImage(rgb_frame.data, w, h, bytes_per_line, QImage.Format_RGB888)\n",
    "        pixmap = QPixmap.fromImage(qt_image)\n",
    "        self.camera_label.setPixmap(pixmap)\n",
    "        \n",
    "    def repaint_interface_label(self, x, y):\n",
    "        pixmap = QPixmap(self.interface_label.size())\n",
    "        pixmap.fill(Qt.transparent)\n",
    "        \n",
    "        painter = QPainter(pixmap)\n",
    "        painter.setBrush(QColor(255, 0, 0))\n",
    "        painter.setPen(Qt.NoPen)\n",
    "        painter.drawEllipse(QPoint(x, y), 10, 10)  # İmleç boyutunu buradan ayarlayabilirsiniz\n",
    "        painter.end()\n",
    "        \n",
    "        self.interface_label.setPixmap(pixmap)\n",
    "\n",
    "    def keyPressEvent(self, event):\n",
    "        if event.key() == Qt.Key_Q:  # Kullanıcı 'q' tuşuna bastığında\n",
    "            self.close()  # Pencereyi kapat\n",
    "        \n",
    "    def closeEvent(self, event):\n",
    "        self.cap.release()\n",
    "        self.face_mesh.close()\n",
    "        event.accept()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app = QApplication(sys.argv)\n",
    "    main_window = CameraFeed()\n",
    "    main_window.show()\n",
    "    sys.exit(app.exec_())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yedekte dursun aşağıdaki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1733693511.211304 2794535 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M2\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1733693511.212966 2794637 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1733693511.217650 2794637 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1733693512.900284 2794639 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n",
      "2024-12-09 00:31:52.943 Python[63337:2794535] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2024-12-09 00:31:52.943 Python[63337:2794535] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ulasyildiz/Documents/Gesture-Based Interaction/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import sys\n",
    "from PyQt5.QtWidgets import QApplication, QLabel, QWidget\n",
    "from PyQt5.QtGui import QImage, QPixmap, QPainter, QColor\n",
    "from PyQt5.QtCore import QTimer, Qt, QPoint\n",
    "\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "\n",
    "\n",
    "class CameraFeed(QWidget):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.setWindowTitle(\"Burun İmleci\")\n",
    "        self.setGeometry(100, 100, 1280, 720)\n",
    "\n",
    "        # Kamera görüntüsü için QLabel\n",
    "        self.camera_label = QLabel(self)\n",
    "        self.camera_label.setFixedSize(320, 240)\n",
    "        self.camera_label.setStyleSheet(\"border: 1px solid black;\")\n",
    "        self.camera_label.move((self.width() - self.camera_label.width()) // 2, 20)\n",
    "\n",
    "        # Arayüz alanı\n",
    "        self.interface_label = QLabel(self)\n",
    "        self.interface_label.setFixedSize(1280, 480)\n",
    "        self.interface_label.setStyleSheet(\"background-color: lightgray; border: 1px solid black;\")\n",
    "        self.interface_label.move(0, self.camera_label.height() + 40)\n",
    "\n",
    "        # İmleç pozisyonu bilgisi\n",
    "        self.cursor_label = QLabel(self)\n",
    "        self.cursor_label.setText(\"Burun İmleci Koordinatları: X: 0, Y: 0\")\n",
    "        self.cursor_label.setStyleSheet(\"font-size: 16px; color: green;\")\n",
    "        self.cursor_label.setGeometry(10, self.interface_label.y() - 30, 400, 30)\n",
    "\n",
    "        # Timer\n",
    "        self.timer = QTimer(self)\n",
    "        self.timer.timeout.connect(self.update_frame)\n",
    "\n",
    "        # Mediapipe FaceMesh\n",
    "        self.face_mesh = mp_face_mesh.FaceMesh(refine_landmarks=True, min_detection_confidence=0.7, min_tracking_confidence=0.7)\n",
    "\n",
    "        # Kamera\n",
    "        self.cap = cv2.VideoCapture(0)\n",
    "        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "        self.timer.start(20)\n",
    "\n",
    "        # Burun imleci pozisyonu\n",
    "        self.cursor_x, self.cursor_y = 0, 0\n",
    "\n",
    "    def update_frame(self):\n",
    "        ret, frame = self.cap.read()\n",
    "        if not ret:\n",
    "            return\n",
    "\n",
    "        # Görüntüyü yatay eksende çevir\n",
    "        frame = cv2.flip(frame, 1)\n",
    "\n",
    "        # BGR -> RGB\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Mediapipe ile yüz analizi\n",
    "        results = self.face_mesh.process(rgb_frame)\n",
    "\n",
    "        if results.multi_face_landmarks:\n",
    "            for face_landmarks in results.multi_face_landmarks:\n",
    "                h, w, c = frame.shape\n",
    "                nose_tip = face_landmarks.landmark[1]  # Burun ucu\n",
    "\n",
    "                self.cursor_x = int(nose_tip.x * self.interface_label.width())\n",
    "                self.cursor_y = int(nose_tip.y * self.interface_label.height())\n",
    "\n",
    "                self.cursor_label.setText(f\"Burun İmleci Koordinatları: X: {self.cursor_x}, Y: {self.cursor_y}\")\n",
    "                self.repaint_interface_label(self.cursor_x, self.cursor_y)\n",
    "\n",
    "        h, w, ch = rgb_frame.shape\n",
    "        bytes_per_line = ch * w\n",
    "        qt_image = QImage(rgb_frame.data, w, h, bytes_per_line, QImage.Format_RGB888)\n",
    "        pixmap = QPixmap.fromImage(qt_image)\n",
    "        self.camera_label.setPixmap(pixmap)\n",
    "\n",
    "    def repaint_interface_label(self, x, y):\n",
    "        pixmap = QPixmap(self.interface_label.size())\n",
    "        pixmap.fill(Qt.transparent)\n",
    "\n",
    "        painter = QPainter(pixmap)\n",
    "        painter.setBrush(QColor(255, 0, 0))\n",
    "        painter.setPen(Qt.NoPen)\n",
    "        painter.drawEllipse(QPoint(x, y), 20, 20)\n",
    "        painter.end()\n",
    "\n",
    "        self.interface_label.setPixmap(pixmap)\n",
    "\n",
    "    def keyPressEvent(self, event):\n",
    "        if event.key() == Qt.Key_Q:\n",
    "            self.close()\n",
    "\n",
    "    def closeEvent(self, event):\n",
    "        self.cap.release()\n",
    "        self.face_mesh.close()\n",
    "        event.accept()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app = QApplication([])\n",
    "    main_window = CameraFeed()\n",
    "    main_window.show()\n",
    "    sys.exit(app.exec_())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kalibrasyon Edilmiş Hali Aşağıda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1733696596.838574 2834685 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M2\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1733696596.840165 2834880 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1733696596.844881 2834878 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "2024-12-09 01:23:18.499 Python[65023:2834685] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2024-12-09 01:23:18.499 Python[65023:2834685] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n",
      "W0000 00:00:1733696598.536335 2834883 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ulasyildiz/Documents/Gesture-Based Interaction/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import sys\n",
    "from PyQt5.QtWidgets import QApplication, QLabel, QWidget\n",
    "from PyQt5.QtGui import QImage, QPixmap, QPainter, QColor\n",
    "from PyQt5.QtCore import QTimer, Qt, QPoint\n",
    "\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "\n",
    "\n",
    "class CameraFeed(QWidget):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.setWindowTitle(\"Burun İmleci\")\n",
    "        self.setGeometry(100, 100, 1280, 720)\n",
    "\n",
    "        # Kamera görüntüsü için QLabel\n",
    "        self.camera_label = QLabel(self)\n",
    "        self.camera_label.setFixedSize(320, 240)\n",
    "        self.camera_label.setStyleSheet(\"border: 1px solid black;\")\n",
    "        self.camera_label.move((self.width() - self.camera_label.width()) // 2, 20)\n",
    "\n",
    "        # Arayüz alanı\n",
    "        self.interface_label = QLabel(self)\n",
    "        self.interface_label.setFixedSize(1280, 400)  # Yükseklik 400'e ayarlandı\n",
    "        self.interface_label.setStyleSheet(\"background-color: lightgray; border: 1px solid black;\")\n",
    "        self.interface_label.move(0, self.camera_label.height() + 40)\n",
    "\n",
    "        # İmleç pozisyonu bilgisi\n",
    "        self.cursor_label = QLabel(self)\n",
    "        self.cursor_label.setText(\"Burun İmleci Koordinatları: X: 640, Y: 200\")  # Başlangıçta ortada\n",
    "        self.cursor_label.setStyleSheet(\"font-size: 16px; color: green;\")\n",
    "        self.cursor_label.setGeometry(10, self.interface_label.y() - 30, 400, 30)\n",
    "\n",
    "        # Timer\n",
    "        self.timer = QTimer(self)\n",
    "        self.timer.timeout.connect(self.update_frame)\n",
    "\n",
    "        # Mediapipe FaceMesh\n",
    "        self.face_mesh = mp_face_mesh.FaceMesh(refine_landmarks=True, min_detection_confidence=0.7, min_tracking_confidence=0.7)\n",
    "\n",
    "        # Kamera\n",
    "        self.cap = cv2.VideoCapture(0)\n",
    "        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "        self.timer.start(20)\n",
    "\n",
    "        # Hassasiyet çarpanları\n",
    "        self.x_sensitivity = 3\n",
    "        self.y_sensitivity = 5\n",
    "\n",
    "        # Burun imleci pozisyonu (Başlangıçta ortada)\n",
    "        self.cursor_x = self.interface_label.width() // 2\n",
    "        self.cursor_y = self.interface_label.height() // 2\n",
    "\n",
    "        # Kamera yüzü ortalamak için kesme oranları\n",
    "        self.crop_x = 0.25  # %25 sağdan ve soldan kırp\n",
    "        self.crop_y = 0.15  # %15 yukarıdan ve aşağıdan kırp\n",
    "\n",
    "    def update_frame(self):\n",
    "        ret, frame = self.cap.read()\n",
    "        if not ret:\n",
    "            return\n",
    "\n",
    "        # Görüntüyü yatay eksende çevir\n",
    "        frame = cv2.flip(frame, 1)\n",
    "\n",
    "        # Görüntüyü ortalamak için kırp\n",
    "        h, w, c = frame.shape\n",
    "        x_start = int(w * self.crop_x)\n",
    "        x_end = w - x_start\n",
    "        y_start = int(h * self.crop_y)\n",
    "        y_end = h - y_start\n",
    "        cropped_frame = frame[y_start:y_end, x_start:x_end]\n",
    "\n",
    "        # BGR -> RGB\n",
    "        rgb_frame = cv2.cvtColor(cropped_frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Mediapipe ile yüz analizi\n",
    "        results = self.face_mesh.process(rgb_frame)\n",
    "\n",
    "        if results.multi_face_landmarks:\n",
    "            for face_landmarks in results.multi_face_landmarks:\n",
    "                h, w, c = cropped_frame.shape\n",
    "                nose_tip = face_landmarks.landmark[1]  # Burun ucu\n",
    "\n",
    "                # Kullanıcının burun koordinatlarını hesapla\n",
    "                new_cursor_x = int(nose_tip.x * self.interface_label.width())\n",
    "                new_cursor_y = int(nose_tip.y * 400)  # Y değeri 0-400 ile sınırlı\n",
    "\n",
    "                # İmlecin başlangıç pozisyonunda hassasiyet uygulanmasın\n",
    "                if new_cursor_x != self.cursor_x or new_cursor_y != self.cursor_y:\n",
    "                    self.cursor_x = int((new_cursor_x - self.interface_label.width() // 2) * self.x_sensitivity + self.interface_label.width() // 2)\n",
    "                    self.cursor_y = int((new_cursor_y - self.interface_label.height() // 2) * self.y_sensitivity + self.interface_label.height() // 2)\n",
    "\n",
    "                # İmleci sınırlar içinde tut\n",
    "                self.cursor_x = max(0, min(self.cursor_x, self.interface_label.width()))\n",
    "                self.cursor_y = max(0, min(self.cursor_y, 400))  # Y sınırı 0-400 arasında\n",
    "\n",
    "                # İmleç pozisyonu bilgisini güncelle\n",
    "                self.cursor_label.setText(f\"Burun İmleci Koordinatları: X: {self.cursor_x}, Y: {self.cursor_y}\")\n",
    "                self.repaint_interface_label(self.cursor_x, self.cursor_y)\n",
    "\n",
    "        # Kamera görüntüsünü PyQt5 QLabel'e aktar\n",
    "        h, w, ch = rgb_frame.shape\n",
    "        bytes_per_line = ch * w\n",
    "        qt_image = QImage(rgb_frame.data, w, h, bytes_per_line, QImage.Format_RGB888)\n",
    "        pixmap = QPixmap.fromImage(qt_image)\n",
    "        self.camera_label.setPixmap(pixmap)\n",
    "\n",
    "    def repaint_interface_label(self, x, y):\n",
    "        pixmap = QPixmap(self.interface_label.size())\n",
    "        pixmap.fill(Qt.transparent)\n",
    "\n",
    "        painter = QPainter(pixmap)\n",
    "        painter.setBrush(QColor(255, 0, 0))\n",
    "        painter.setPen(Qt.NoPen)\n",
    "        painter.drawEllipse(QPoint(x, y), 20, 20)\n",
    "        painter.end()\n",
    "\n",
    "        self.interface_label.setPixmap(pixmap)\n",
    "\n",
    "    def keyPressEvent(self, event):\n",
    "        if event.key() == Qt.Key_Q:\n",
    "            self.close()\n",
    "\n",
    "    def closeEvent(self, event):\n",
    "        self.cap.release()\n",
    "        self.face_mesh.close()\n",
    "        event.accept()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app = QApplication([])\n",
    "    main_window = CameraFeed()\n",
    "    main_window.show()\n",
    "    sys.exit(app.exec_())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arayüze tuş ekleme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1733697385.551510 2844555 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M2\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1733697385.553243 2844693 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1733697385.558110 2844693 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1733697387.251958 2844695 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n",
      "2024-12-09 01:36:27.292 Python[65435:2844555] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2024-12-09 01:36:27.292 Python[65435:2844555] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ulasyildiz/Documents/Gesture-Based Interaction/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import sys\n",
    "from PyQt5.QtWidgets import QApplication, QLabel, QWidget\n",
    "from PyQt5.QtGui import QImage, QPixmap, QPainter, QColor, QPen\n",
    "from PyQt5.QtCore import QTimer, Qt, QPoint\n",
    "import time\n",
    "\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "\n",
    "\n",
    "class CameraFeed(QWidget):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.setWindowTitle(\"Burun İmleci\")\n",
    "        self.setGeometry(100, 100, 1280, 720)\n",
    "\n",
    "        # Kamera görüntüsü için QLabel\n",
    "        self.camera_label = QLabel(self)\n",
    "        self.camera_label.setFixedSize(320, 240)\n",
    "        self.camera_label.setStyleSheet(\"border: 1px solid black;\")\n",
    "        self.camera_label.move((self.width() - self.camera_label.width()) // 2, 20)\n",
    "\n",
    "        # Arayüz alanı\n",
    "        self.interface_label = QLabel(self)\n",
    "        self.interface_label.setFixedSize(1280, 400)\n",
    "        self.interface_label.setStyleSheet(\"background-color: lightgray; border: 1px solid black;\")\n",
    "        self.interface_label.move(0, self.camera_label.height() + 40)\n",
    "\n",
    "        # İmleç pozisyonu bilgisi\n",
    "        self.cursor_label = QLabel(self)\n",
    "        self.cursor_label.setText(\"Burun İmleci Koordinatları: X: 640, Y: 200\")\n",
    "        self.cursor_label.setStyleSheet(\"font-size: 16px; color: green;\")\n",
    "        self.cursor_label.setGeometry(10, self.interface_label.y() - 30, 400, 30)\n",
    "\n",
    "        # Tebrikler mesajı\n",
    "        self.congratulations_label = QLabel(self)\n",
    "        self.congratulations_label.setText(\"\")\n",
    "        self.congratulations_label.setStyleSheet(\"font-size: 24px; color: blue; font-weight: bold;\")\n",
    "        self.congratulations_label.setGeometry(400, self.interface_label.y() + 50, 500, 50)\n",
    "        self.congratulations_label.setAlignment(Qt.AlignCenter)\n",
    "\n",
    "        # Buton\n",
    "        self.button_x, self.button_y = 500, 150  # Butonun başlangıç koordinatları\n",
    "        self.button_width, self.button_height = 200, 100\n",
    "\n",
    "        # Timer\n",
    "        self.timer = QTimer(self)\n",
    "        self.timer.timeout.connect(self.update_frame)\n",
    "\n",
    "        # Mediapipe FaceMesh\n",
    "        self.face_mesh = mp_face_mesh.FaceMesh(refine_landmarks=True, min_detection_confidence=0.7, min_tracking_confidence=0.7)\n",
    "\n",
    "        # Kamera\n",
    "        self.cap = cv2.VideoCapture(0)\n",
    "        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "        self.timer.start(20)\n",
    "\n",
    "        # Hassasiyet çarpanları\n",
    "        self.x_sensitivity = 3\n",
    "        self.y_sensitivity = 5\n",
    "\n",
    "        # Burun imleci pozisyonu\n",
    "        self.cursor_x = self.interface_label.width() // 2\n",
    "        self.cursor_y = self.interface_label.height() // 2\n",
    "\n",
    "        # Kamera yüzü ortalamak için kesme oranları\n",
    "        self.crop_x = 0.25\n",
    "        self.crop_y = 0.15\n",
    "\n",
    "        # Tıklama işlemi\n",
    "        self.hover_start_time = None\n",
    "        self.hover_duration = 3  # 3 saniye\n",
    "\n",
    "    def update_frame(self):\n",
    "        ret, frame = self.cap.read()\n",
    "        if not ret:\n",
    "            return\n",
    "\n",
    "        # Görüntüyü yatay eksende çevir\n",
    "        frame = cv2.flip(frame, 1)\n",
    "\n",
    "        # Görüntüyü kırp\n",
    "        h, w, c = frame.shape\n",
    "        x_start = int(w * self.crop_x)\n",
    "        x_end = w - x_start\n",
    "        y_start = int(h * self.crop_y)\n",
    "        y_end = h - y_start\n",
    "        cropped_frame = frame[y_start:y_end, x_start:x_end]\n",
    "\n",
    "        # BGR -> RGB\n",
    "        rgb_frame = cv2.cvtColor(cropped_frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Mediapipe ile yüz analizi\n",
    "        results = self.face_mesh.process(rgb_frame)\n",
    "\n",
    "        if results.multi_face_landmarks:\n",
    "            for face_landmarks in results.multi_face_landmarks:\n",
    "                h, w, c = cropped_frame.shape\n",
    "                nose_tip = face_landmarks.landmark[1]\n",
    "\n",
    "                new_cursor_x = int(nose_tip.x * self.interface_label.width())\n",
    "                new_cursor_y = int(nose_tip.y * 400)\n",
    "\n",
    "                if new_cursor_x != self.cursor_x or new_cursor_y != self.cursor_y:\n",
    "                    self.cursor_x = int((new_cursor_x - self.interface_label.width() // 2) * self.x_sensitivity + self.interface_label.width() // 2)\n",
    "                    self.cursor_y = int((new_cursor_y - self.interface_label.height() // 2) * self.y_sensitivity + self.interface_label.height() // 2)\n",
    "\n",
    "                # Sınırlandırma\n",
    "                self.cursor_x = max(0, min(self.cursor_x, self.interface_label.width()))\n",
    "                self.cursor_y = max(0, min(self.cursor_y, 400))\n",
    "\n",
    "                # Tıklama işlemi kontrolü\n",
    "                self.check_hover()\n",
    "\n",
    "                # İmleç pozisyonu bilgisini güncelle\n",
    "                self.cursor_label.setText(f\"Burun İmleci Koordinatları: X: {self.cursor_x}, Y: {self.cursor_y}\")\n",
    "                self.repaint_interface_label(self.cursor_x, self.cursor_y)\n",
    "\n",
    "        # Kamera görüntüsünü QLabel'e aktar\n",
    "        h, w, ch = rgb_frame.shape\n",
    "        bytes_per_line = ch * w\n",
    "        qt_image = QImage(rgb_frame.data, w, h, bytes_per_line, QImage.Format_RGB888)\n",
    "        pixmap = QPixmap.fromImage(qt_image)\n",
    "        self.camera_label.setPixmap(pixmap)\n",
    "\n",
    "    def check_hover(self):\n",
    "        # İmleç buton üzerinde mi?\n",
    "        if self.button_x <= self.cursor_x <= self.button_x + self.button_width and \\\n",
    "                self.button_y <= self.cursor_y <= self.button_y + self.button_height:\n",
    "            if self.hover_start_time is None:\n",
    "                self.hover_start_time = time.time()\n",
    "            elif time.time() - self.hover_start_time >= self.hover_duration:\n",
    "                self.show_congratulations()\n",
    "                self.hover_start_time = None  # Tekrar tıklamayı engellemek için sıfırla\n",
    "        else:\n",
    "            self.hover_start_time = None\n",
    "\n",
    "    def show_congratulations(self):\n",
    "        self.congratulations_label.setText(\"Tebrikler!\")  # Tebrikler mesajını göster\n",
    "        QTimer.singleShot(2000, lambda: self.congratulations_label.setText(\"\"))  # Mesajı 2 saniye sonra sil\n",
    "\n",
    "    def repaint_interface_label(self, x, y):\n",
    "        pixmap = QPixmap(self.interface_label.size())\n",
    "        pixmap.fill(Qt.transparent)\n",
    "\n",
    "        painter = QPainter(pixmap)\n",
    "\n",
    "        # Buton çiz\n",
    "        painter.setBrush(QColor(0, 255, 0))\n",
    "        painter.drawRect(self.button_x, self.button_y, self.button_width, self.button_height)\n",
    "\n",
    "        # İmleç çemberi çiz\n",
    "        painter.setBrush(QColor(255, 0, 0))\n",
    "        painter.setPen(Qt.NoPen)\n",
    "        painter.drawEllipse(QPoint(x, y), 20, 20)\n",
    "\n",
    "        # Animasyon - Çevresel sınır dolması\n",
    "        if self.hover_start_time:\n",
    "            elapsed = time.time() - self.hover_start_time\n",
    "            progress = int((elapsed / self.hover_duration) * 360)\n",
    "            pen = QPen(QColor(0, 0, 255), 3)\n",
    "            painter.setPen(pen)\n",
    "            painter.drawArc(x - 30, y - 30, 60, 60, 0, progress * 16)\n",
    "\n",
    "        painter.end()\n",
    "        self.interface_label.setPixmap(pixmap)\n",
    "\n",
    "    def keyPressEvent(self, event):\n",
    "        if event.key() == Qt.Key_Q:\n",
    "            self.close()\n",
    "\n",
    "    def closeEvent(self, event):\n",
    "        self.cap.release()\n",
    "        self.face_mesh.close()\n",
    "        event.accept()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app = QApplication([])\n",
    "    main_window = CameraFeed()\n",
    "    main_window.show()\n",
    "    sys.exit(app.exec_())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
